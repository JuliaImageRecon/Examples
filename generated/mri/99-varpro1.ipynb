{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Variable Projection: One exponential\n",
    "\n",
    "Illustrate fitting one exponential to data.\n",
    "\n",
    "See:\n",
    "- [VarPro blog](https://geo-ant.github.io/blog/2020/variable-projection-part-1-fundamentals)\n",
    "- [VP4Optim.jl](https://github.com/cganter/VP4Optim.jl) has biexponential fits\n",
    "- [Varpro.jl](https://github.com/macd/Varpro.jl)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Packages needed here."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ImagePhantoms: ellipse, ellipse_parameters, phantom, SheppLoganBrainWeb\n",
    "using Statistics: mean, std\n",
    "using Plots: default, gui, histogram, plot, plot!, scatter, scatter!\n",
    "using Plots: cgrad, RGB\n",
    "default(markerstrokecolor=:auto, label=\"\", widen = true)\n",
    "using LaTeXStrings\n",
    "using LinearAlgebra: norm, Diagonal, diag, diagm\n",
    "using MIRTjim: jim\n",
    "using Random: seed!; seed!(0)\n",
    "using Unitful: @u_str, uconvert, ustrip, ms, s, mm\n",
    "using InteractiveUtils: versioninfo"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single exponential\n",
    "\n",
    "We explore a simple case:\n",
    "fitting a single exponential to some noisy data:\n",
    "$y_m = x e^{- r t_m} + ϵ_m$\n",
    "for $m = 1,…,M$.\n",
    "The two unknown parameters here are:\n",
    "- the decay rate $r ≥ 0$\n",
    "- the amplitude $x$ (that could be complex in some MRI settings)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Tf = Float32\n",
    "Tc = Complex{Tf}\n",
    "M = 8 # how many samples\n",
    "Δte = 25ms # echo spacing\n",
    "te1 = 5ms # time of first echo\n",
    "tm = Tf.(te1 .+ (0:(M-1)) * Δte) # echo times\n",
    "x_true = 100 # AU\n",
    "r_true = 20/s\n",
    "signal(x, r; t=tm) = x * exp.(-t * r) # signal model\n",
    "y_true = signal(x_true, r_true)\n",
    "tf = range(0, M, 201) * Δte\n",
    "xaxis_t = (\"t\", (0,200).*ms, [0ms; tm; M*Δte])\n",
    "py = plot( xaxis = xaxis_t )\n",
    "plot!(py, tf, signal(x_true, r_true; t=tf), color=:black)\n",
    "scatter!(py, tm, y_true, label = \"Noiseless data, M=$M samples\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random phase and noise\n",
    "Actual MRI data has some phase and noise."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "phase_true = rand() * 2π + 0π\n",
    "y_true_phased = Tc.(cis(phase_true) * y_true)\n",
    "\n",
    "snr = 25 # dB\n",
    "snr2sigma(db, y) = 10^(-db/20) * norm(y) / sqrt(length(y))\n",
    "σ = Tf(snr2sigma(snr, y_true_phased))\n",
    "yc = y_true_phased + σ * randn(Tc, M)\n",
    "@show 20 * log10(norm(yc) / norm(yc - y_true_phased)) # check σ\n",
    "\n",
    "pp = scatter(tm, angle.(y_true_phased), label = \"True data\",\n",
    " xaxis = xaxis_t,\n",
    " yaxis = (\"Phase\", (-π, π), ((-1:1)*π, [\"-π\", \"0\", \"π\"])),\n",
    ")\n",
    "scatter!(tm, angle.(yc), label=\"Noisy data\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The phase of the noisy data becomes unreliable for low signal values"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pc = scatter(tm, real(yc),\n",
    " label = \"Noisy data - real part\",\n",
    " xaxis = xaxis_t,\n",
    " ylim = (-100, 100),\n",
    ")\n",
    "scatter!(pc, tm, imag(yc),\n",
    " label = \"Noisy data - imag part\",\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Phase correction\n",
    "Phase correct signal using phase of first (noisy) data point"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "yr = conj(sign(yc[1])) .* yc\n",
    "\n",
    "pr = deepcopy(py)\n",
    "scatter!(pr, tm, real(yr),\n",
    " label = \"Phase corrected data - real part\",\n",
    " xaxis = xaxis_t,\n",
    " ylim = (-5, 105),\n",
    " marker = :square,\n",
    ")\n",
    "scatter!(pr, tm, imag(yr),\n",
    " label = \"Phase corrected data - imag part\",\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examine the distribution of real part after phase correction"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function make1_phase_corrected_signal()\n",
    "    phase_true = rand() * 2π\n",
    "    y_true_phased = Tc.(cis(phase_true) * y_true)\n",
    "    yc = y_true_phased + σ * randn(Tc, M)\n",
    "    yr = conj(sign(yc[1])) .* yc\n",
    "end\n",
    "\n",
    "N = 2000\n",
    "ysim = stack(_ -> make1_phase_corrected_signal(), 1:N)\n",
    "tmp = ysim[end,:]\n",
    "\n",
    "pe = scatter(real(tmp), imag(tmp), aspect_ratio=1,\n",
    " xaxis = (\"real(y_$M)\", (-4,8), -3:8),\n",
    " yaxis = (\"imag(y_$M)\", (-6,6), -5:5),\n",
    ")\n",
    "plot!(pe, real(y_true[end]) * [1,1], [-5, 5])\n",
    "plot!(pe, [-5, 5] .+ 3, imag(y_true[end]) * [1,1])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Histogram of the real part looks reasonably Gaussian"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ph = histogram((real(tmp) .- real(y_true[end])) / (σ/√2), bins=-4:0.1:4,\n",
    " xlabel = \"Real part of phase-corrected signal y_$M\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log-linear fit\n",
    "LS fitting using log of absolute value of real part\n",
    "of phase-corrected data."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "yl = @. log(abs(yr))\n",
    "pl = plot(xaxis=xaxis_t, yaxis=(\"Log data\"))\n",
    "log_fine = log.(signal(x_true, r_true; t=tf))\n",
    "plot!(pl, tf, log_fine, color=:lightgray)\n",
    "scatter!(pl, tm, log.(y_true), label=\"True\", color=:black)\n",
    "scatter!(pl, tm, yl, label=\"Noisy\", color=:red)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear (not affine!) fit,\n",
    "after normalizing data by 1st data point\n",
    "(which is a bit smaller than `x_true`\n",
    "since first sample is not at $t=0$)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tm_diff = tm .- te1 # time shift by 1st echo\n",
    "A1 = reshape(-tm_diff, M, 1)\n",
    "yl0 = yl .- yl[1] # normalize\n",
    "A1pinv = inv(A1'*A1) * A1'\n",
    "r1 = A1pinv * yl0\n",
    "r1 = only(r1)\n",
    "\n",
    "Ts = u\"s^-1\"\n",
    "xaxis_td = (\"Δt\", (0,195).*ms, [0ms; tm_diff; M*Δte])\n",
    "pf1 = plot(xaxis=xaxis_td, yaxis=(\"Log data\"))\n",
    "plot!(pf1, tf .- te1, log_fine .- log(y_true[1]), color=:lightgray)\n",
    "scatter!(pf1, tm_diff, log.(y_true/y_true[1]),\n",
    " label=\"True for R1=$r_true\", color=:black)\n",
    "scatter!(pf1, tm_diff, yl0, label = \"Noisy\", color=:red)\n",
    "roundr(rate) = round(Ts, Float64(Ts(rate)), digits=2)\n",
    "plot!(pf1, tf .- te1, -r1 .* (tf .- te1),\n",
    " label = \"Linear Fit: R1 = $(roundr(r1))\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Maybe that poor fit was just one unlucky trial?\n",
    "Repeat the log-linear fit many times."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ysim_log = log.(abs.(ysim))\n",
    "ysim_log .-= ysim_log[1,:]'\n",
    "r1sim = vec(A1pinv * ysim_log)\n",
    "r1sim = Ts.(r1sim)\n",
    "\n",
    "ph1 = histogram(r1sim, bins=16:0.2:32,\n",
    " label = \"Mean=$(roundr(mean(r1sim))), σ=$(roundr(std(r1sim)))\",\n",
    " xaxis = (\"R1 estimate via log-linear fit\", (16, 32)./s, (16:2:32)./s),\n",
    ")\n",
    "plot!(r_true*[1,1], [0, 140])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CRB\n",
    "Compute CRB for precision of unbiased estimator.\n",
    "This requires inverting the Fisher information matrix.\n",
    "Here the Fisher information matrix has units,\n",
    "so Julia's built-in inverse `inv` does not work.\n",
    "See 2.4.5.2 of Fessler 2024 book for tips."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Matrix inverse for matrix whose units are suitable for inversion,\n",
    "meaning `X = Diag(left) * Z * Diag(right)`\n",
    "where `Z` is unitless and `left` and `right` are vectors with units.\n",
    "(Fisher information matrices always have this structure.)\n",
    "\"\"\"\n",
    "function inv_unitful(X::Matrix{<:Number})\n",
    "    right = oneunit.(X[1,:]) # units for \"right side\" of matrix\n",
    "    left = oneunit.(X[:,1] / right[1]) # units for \"left side\" of matrix\n",
    "    N = size(X,1)\n",
    "    Z = [X[i,j] / (left[i] * right[j]) for i in 1:N, j in 1:N]\n",
    "    Zinv = inv(Z) # Z should be unitless if X has inverse-appropriate units\n",
    "    Xinv = [Zinv[i,j] / (right[i] * left[j]) for i in 1:N, j in 1:N]\n",
    "    return Xinv\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gradients of `y_true = x_true * exp.(- r_true * tm)`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "grad1 = @. exp(-r_true * tm) # x\n",
    "grad2 = @. -x_true * tm * exp(-r_true * tm) # r\n",
    "grad = [grad1 grad2]\n",
    "fish1 = grad' * grad / σ^2"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute CRB from Fisher information via unitful matrix inverse"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "crb = inv_unitful(fish1)\n",
    "crb_r1 = Ts(sqrt(crb[2,2]))\n",
    "crb_r1_xknown = Ts(sqrt(1/fish1[2,2])) # CRB if M0 is known, about 0.72\n",
    "\n",
    "plot!(annotation = (27, 100,\n",
    " \"CRB = $(roundr(crb_r1)) or $(roundr(crb_r1_xknown))\", :red))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Log-linear fit to early echoes\n",
    "Try discarding some of the later echoes\n",
    "that have worse SNR.\n",
    "The results depend a lot on how many echoes are used.\n",
    "In this case, K = 4 or 5 works well,\n",
    "but how would you know in practice?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "K = 3 # keep first few echos\n",
    "A1K = A1[1:K,:]\n",
    "A1pinvK = inv(A1K'*A1K) * A1K'\n",
    "r1simK = vec(A1pinvK * ysim_log[1:K,:])\n",
    "r1simK = Ts.(r1simK)\n",
    "\n",
    "phK = histogram(r1simK, bins=16:0.2:32,\n",
    " label = \"Mean=$(roundr(mean(r1simK))), σ=$(roundr(std(r1simK)))\",\n",
    " xaxis = (\"R1 estimate via log-linear fit K=$K\", (16, 32)./s, (16:2:32)./s),\n",
    ")\n",
    "plot!(r_true*[1,1], [0, 140])\n",
    "plot!(annotation = (27, 100,\n",
    " \"CRB = $(roundr(crb_r1)) or $(roundr(crb_r1_xknown))\", :red))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare to dictionary matching\n",
    "This approach is essentially a quantized maximum-likelihood estimator.\n",
    "Here the quantization interval of 0.1/s\n",
    "turns out to be much smaller\n",
    "than the estimator standard deviation of 0.6/s,\n",
    "so the quantization error seems negligible.\n",
    "\n",
    "It is essential to normalize the dictionary atoms\n",
    "by the Euclidean norm.\n",
    "The reason why is exactly the same as the\n",
    "[VarPro](https://doi.org/10.1088/0266-5611/19/2/201)\n",
    "derivation."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r_list = range(0/s, 40/s, 401) # linear spacing?\n",
    "dict = signal(1, r_list')\n",
    "dict_norm = dict ./ norm.(eachcol(dict))'\n",
    "pd = plot(\n",
    "  plot(tm, dict[:,1:10:end], title=\"Dictionary\"),\n",
    "  plot(tm, dict_norm[:,1:10:end], title=\"Normalized Dictionary\"),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inner products with (normalized) dictionary atoms"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tmp = dict_norm' * real(ysim)\n",
    "tmp = argmax.(eachcol(tmp)) # find max\n",
    "r_dm = r_list[tmp]; # R2 value from dictionary\n",
    "\n",
    "ph_dm = histogram(r_dm, bins=16:0.2:32,\n",
    " label = \"Mean=$(roundr(mean(r_dm))), σ=$(roundr(std(r_dm)))\",\n",
    " xaxis = (\"R1 estimate via dictionary matching\", (16, 32)./s, (16:2:32)./s),\n",
    ")\n",
    "plot!(r_true*[1,1], [0, 140])\n",
    "plot!(annotation = (27, 100,\n",
    " \"CRB = $(roundr(crb_r1)) or $(roundr(crb_r1_xknown))\", :red))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WLS for log-linear fit\n",
    "Compare to WLS via error propagation\n",
    "Much faster than dictionary matching!\n",
    "\n",
    "Derive weights.\n",
    "The log of the normalized signal value\n",
    "(ignoring phase correction and the absolute value)\n",
    "is approximately\n",
    "(using a 1st-order Taylor expansion)\n",
    "$$\n",
    "v_m\n",
    "= \\log(y_m / y_1)\n",
    "= \\log(y_m) - \\log(y_1)\n",
    "≈ \\log(\\bar{y}_m) - \\log(\\bar{y}_1)\n",
    "+ (1/\\bar{y}_m) (y_m - \\bar{y}_m)\n",
    "- (1/\\bar{y}_1) (y_1 - \\bar{y}_1)\n",
    "$$\n",
    "so the variance of that log value is\n",
    "$$\n",
    "\\mathrm{Var}(v_m)\n",
    "≈ (1/\\bar{y}_m^2) \\, \\mathrm{Var}(y_m - \\bar{y}_m)\n",
    "+ (1/\\bar{y}_1^2) \\, \\mathrm{Var}(y_1 - \\bar{y}_1)\n",
    "= σ^2 \\, ( 1/\\bar{y}_m^2 + 1/\\bar{y}_1^2 ) .\n",
    "$$\n",
    "We would like to perform the WLS fit\n",
    "using the reciprocal of that variance.\n",
    "However,\n",
    "the expected values\n",
    "$\\bar{y}_m = \\mathbb{E}(y_m)$ are unknown\n",
    "because they depend\n",
    "on the latent parameter(s).\n",
    "\n",
    "In practice we use a \"plug-in\" estimate\n",
    "using the observed data\n",
    "in place of the expectation:\n",
    "$$\n",
    "w_m = 1 / ( 1/y_m^2 + 1/y_1^2 ) .\n",
    "$$\n",
    "The noise variance $σ^2$ is the same for all $m$\n",
    "so it is irrelevant to the WLS fit:\n",
    "$$\n",
    "\\arg\\min_{x} (A x - b)' W (A x - b)\n",
    "$$\n",
    "where here $b$ is the log normalized data\n",
    "$b_m = \\log(y_m / y_1)$\n",
    "and $x$ here denotes the rate parameter $r$.\n",
    "\n",
    "For $m=1$ we have $v_1 = 1$ by construction,\n",
    "which has zero variance.\n",
    "Our log-linear model\n",
    "$-r Δt$\n",
    "is explicitly $0$ at $Δt_1 = 0$,\n",
    "i.e., $A_{1,1} = 0$,\n",
    "so that first (normalized) data point provides no information\n",
    "and is inherently excluded\n",
    "from the linear fit\n",
    "(for any weighting)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "   wls_exp_fit(y)\n",
    "Fit rate of a single exponential using weighted least-squares (WLS)\n",
    "Expects non-log data.\n",
    "Uses global `A1`.\n",
    "Returns scalar rate estimate.\n",
    "\"\"\"\n",
    "function wls_exp_fit(y)\n",
    "    w = @. (1 / y^2 + 1 / y[1]^2) # drop irrelevant σ^2\n",
    "    w = 1 ./ w # weights via 1st-order Taylor approx\n",
    "    A1w = w .* A1\n",
    "    ylog = @. log(abs(y ./ y[1]))\n",
    "    return only(A1w' * ylog) / only(A1w' * A1)\n",
    "end\n",
    "\n",
    "r1_wls = Ts.(wls_exp_fit.(real(eachcol(ysim))))\n",
    "\n",
    "ph_wls = histogram(r1_wls, bins=16:0.2:32,\n",
    " label = \"Mean=$(roundr(mean(r1_wls))), σ=$(roundr(std(r1_wls)))\",\n",
    " xaxis = (\"R1 estimate via log-WLS\", (16, 32)./s, (16:2:32)./s),\n",
    ")\n",
    "plot!(r_true*[1,1], [0, 270])\n",
    "plot!(annotation = (27, 100,\n",
    " \"CRB = $(roundr(crb_r1)) or $(roundr(crb_r1_xknown))\", :red))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Phantom illustration"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r2_values = [20, 0, -3, -4, 5, 6, 7, 8, 9, -2] / s\n",
    "fovs = (256mm, 256mm)\n",
    "params = ellipse_parameters(SheppLoganBrainWeb(); fovs, disjoint=true)\n",
    "params = [(p[1:5]..., r2_values[i]) for (i, p) in enumerate(params)]\n",
    "ob = ellipse(params)\n",
    "y = range(-fovs[2]/2, fovs[2]/2, 256)\n",
    "x = range(-205/2, 205/2, 206) * (y[2]-y[1])\n",
    "oversample = 3\n",
    "r2_map_true = phantom(x, y, ob[1:1], 1) + # trick to avoid edge issues\n",
    "    phantom(x, y, ob[3:end], oversample)\n",
    "mask = r2_map_true .> 0/s\n",
    "x_map_true = @. 100 * mask * cis(π/2 + x / 100mm) # non-uniform phase\n",
    "\n",
    "climr = (0,30) ./ s\n",
    "p2r = jim(x, y, r2_map_true, \"R2* Map\";\n",
    " clim = climr, xlabel=\"x\", ylabel=\"y\", color=:cividis)\n",
    "p2 = plot(\n",
    " p2r,\n",
    " jim(x, y, x_map_true, \"|M0 Map|\"; xlabel=\"x\", ylabel=\"y\"),\n",
    " jim(x, y, angle.(x_map_true), \"∠M0 Map\"; xlabel=\"x\", ylabel=\"y\", color=:hsv);\n",
    " layout = (1,3), size=(800,300),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simulate multi-echo data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y_true_phantom = signal.(x_map_true, r2_map_true)\n",
    "y_true_phantom = stack(y_true_phantom)\n",
    "y_true_phantom = permutedims(y_true_phantom, [2, 3, 1]) # (nx,ny,M)\n",
    "dim = size(y_true_phantom)\n",
    "y_phantom = y_true_phantom + σ * randn(Tc, dim...)\n",
    "\n",
    "pyp = plot(\n",
    " jim(x, y, y_phantom; title=\"|Echo images|\"),\n",
    " jim(x, y, angle.(y_phantom); title=\"∠Echo images\", color=:hsv),\n",
    " layout = (1,2), size=(800,300),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Phase correct"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y_phantom_dephased = @. conj(sign(y_phantom[:,:,1])) * y_phantom\n",
    "jim(x, y, angle.(y_phantom_dephased); title=\"∠Echo images after dephasing\", color=:hsv)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take real part"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y_phantom_realed = real(y_phantom_dephased)\n",
    "jim(x, y, y_phantom_realed; title=\"Real(Echo images) after dephasing\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "WLS estimate of R2* from real part"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r2_map_wls = Ts.(wls_exp_fit.(eachslice(y_phantom_realed; dims=(1,2))))\n",
    "r2_map_wls .*= mask\n",
    "RGB255(args...) = RGB((args ./ 255)...)\n",
    "ecolor = cgrad([RGB255(230, 80, 65), :black, RGB255(23, 120, 232)])\n",
    "rmse = sqrt(mean(abs2.(r2_map_wls[mask] - r2_map_true[mask])))\n",
    "plot(p2r,\n",
    " jim(x, y, r2_map_wls, \"R2* Map via WLS\";\n",
    "  clim = climr, xlabel=\"x\", ylabel=\"y\", color=:cividis),\n",
    " jim(x, y, r2_map_wls - r2_map_true, \"R2* Error \\n RMSE=$(roundr(rmse))\";\n",
    "  clim = (-3, 3) ./ s, color=ecolor);\n",
    " layout = (1,3), size=(800,300),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Future work\n",
    "\n",
    "- affine fit via LS and WLS and ML\n",
    "\n",
    "Biexponential case:\n",
    "- Compare to ML via VarPro\n",
    "- Compare to ML via NLS\n",
    "- Cost contours, before and after eliminating x\n",
    "- MM approach?\n",
    "- GD?\n",
    "- Newton's method?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "include(\"../../../inc/reproduce.jl\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.0"
  },
  "kernelspec": {
   "name": "julia-1.12",
   "display_name": "Julia 1.12.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}